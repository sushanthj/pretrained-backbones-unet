{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNet with Resnet 50 Backbone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Dataset Size: \n",
    "\n",
    "Val Dataset Size: \n",
    "\n",
    "Test Dataset Size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install torch -q\n",
    "# %pip install opencv-python -q\n",
    "# %pip install pycocotools -q\n",
    "# %pip install timm==0.6.12 -q\n",
    "# %pip install ipdb -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from backbones_unet.model.unet import Unet\n",
    "from backbones_unet.utils.dataset import SemanticSegmentationDataset\n",
    "from backbones_unet.model.losses import DiceLoss\n",
    "from backbones_unet.utils.trainer import Trainer\n",
    "from torchsummaryX import summary\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from convert_coco_ann_to_mask import convert_coco_to_mask\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "import torchvision\n",
    "import torch\n",
    "import os\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.3350,  0.7661,  2.0227,  ..., -0.3498, -0.7951, -0.7265],\n",
      "          [ 0.4971,  1.7222,  1.2369,  ..., -0.7160, -0.8351, -0.7102],\n",
      "          [-0.0191,  2.0960,  2.4046,  ..., -0.0222, -0.5633, -0.0805],\n",
      "          ...,\n",
      "          [ 0.7047,  0.4139,  1.2986,  ...,  0.1282, -0.5849, -0.7071],\n",
      "          [ 1.2121,  0.6142,  0.3822,  ..., -0.1689, -0.2055, -0.1425],\n",
      "          [ 0.4498, -0.0710,  0.3296,  ...,  0.8667,  0.3907,  0.3441]]]])\n"
     ]
    }
   ],
   "source": [
    "# Test Installation\n",
    "random_tensor = torch.rand((1, 3, 64, 64))\n",
    "model = Unet(in_channels=3, num_classes=1) # if no backbone specified, will default to Resnet50\n",
    "print(model.predict(random_tensor))\n",
    "# summary(model, random_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to add more items here\n",
    "config = {\n",
    "    \"lr\"         : 1e-4,\n",
    "    \"epochs\"     : 100,\n",
    "    \"batch_size\" : 1,  # Increase if your device can handle it\n",
    "    \"num_classes\": 1,\n",
    "    'truncated_normal_mean' : 0,\n",
    "    'truncated_normal_std' : 0.2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a torch.utils.data.Dataset/DataLoader\n",
    "annotation_json_path = '/home/sush/klab2/rosbags_collated/sensors_2023-08-03-15-19-03_0/annotation.json'\n",
    "train_img_path = '/home/sush/klab2/rosbags_collated/sensors_2023-08-03-15-19-03_0/images'\n",
    "train_mask_path = '/home/sush/klab2/rosbags_collated/sensors_2023-08-03-15-19-03_0/masks'\n",
    "\n",
    "train_img_path_for_ImageFolder_dataloader = '/home/sush/klab2/rosbags_collated/sensors_2023-08-03-15-19-03_0/images_with_class/'\n",
    "\n",
    "#! Temporarily using train and val images as same\n",
    "val_img_path = '/home/sush/klab2/rosbags_collated/sensors_2023-08-03-15-19-03_0/images'\n",
    "val_mask_path = '/home/sush/klab2/rosbags_collated/sensors_2023-08-03-15-19-03_0/masks'\n",
    "\n",
    "test_img_path = '/home/sush/klab2/rosbags_collated/sensors_2023-08-03-15-19-03_0/images'\n",
    "\n",
    "# img_size = (1384, 1032) # = width, height            # currently PtGrey images\n",
    "img_size = (1024, 1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Masks from the COCO annotations (if not already done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert_coco_to_mask(input_json=annotation_json_path, image_folder=train_img_path, output_folder=train_mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find mean and std of your dataset:\n",
    "def get_mean_and_std_calculated(IMAGE_DATA_DIR):\n",
    "    \"\"\"\n",
    "    NOTE: The ImageFolder dataloader requires the following file structure:\n",
    "\n",
    "    root\n",
    "    |\n",
    "    └── cat (class label)\n",
    "        |\n",
    "        ├──img_2.png\n",
    "        └──img_1.png\n",
    "\n",
    "    \"\"\"\n",
    "    train_dataset = ImageFolder(IMAGE_DATA_DIR, transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "    # Initialize lists to store channel-wise means and standard deviations\n",
    "    channel_wise_means = [0.0, 0.0, 0.0]\n",
    "    channel_wise_stds = [0.0, 0.0, 0.0]\n",
    "\n",
    "    # Iterate through the training dataset to calculate means and standard deviations\n",
    "    for image, _ in train_dataset:\n",
    "        for i in range(3):  # Assuming RGB images\n",
    "            channel_wise_means[i] += image[i, :, :].mean().item()\n",
    "            channel_wise_stds[i] += image[i, :, :].std().item()\n",
    "\n",
    "    # Calculate the mean and standard deviation for each channel\n",
    "    num_samples = len(train_dataset)\n",
    "    channel_wise_means = [mean / num_samples for mean in channel_wise_means]\n",
    "    channel_wise_stds = [std / num_samples for std in channel_wise_stds]\n",
    "\n",
    "    # Print the mean and standard deviation for each channel\n",
    "    print(\"Mean:\", channel_wise_means)\n",
    "    print(\"Std:\", channel_wise_stds)\n",
    "\n",
    "    return channel_wise_means, channel_wise_stds\n",
    "\n",
    "# means, stds = get_mean_and_std_calculated(train_img_path_for_ImageFolder_dataloader)\n",
    "means = [0.44895144719250346, 0.4951483853617493, 0.4498602793532975]\n",
    "stds = [0.21388493326245522, 0.24571933703763144, 0.22413276759337405]\n",
    "\n",
    "normalize_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Normalize(mean=means, std=stds) # always normalize only after tensor conversion\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomHorizontalFlip(0.5),\n",
    "    torchvision.transforms.ColorJitter(brightness=0.16, contrast=0.15, saturation=0.1),\n",
    "    torchvision.transforms.RandomRotation(18),\n",
    "    torchvision.transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "    torchvision.transforms.RandomPerspective(distortion_scale=0.2, p=0.2),\n",
    "])\n",
    "\n",
    "train_dataset = SemanticSegmentationDataset(img_paths=train_img_path, mask_paths=train_mask_path, size=img_size, mode='binary', normalize=normalize_transform, transformations=train_transforms)\n",
    "val_dataset = SemanticSegmentationDataset(img_paths=val_img_path, mask_paths=val_mask_path, size=img_size, mode='binary', normalize=normalize_transform, transformations=None)\n",
    "test_dataset = SemanticSegmentationDataset(img_paths=val_img_path, mask_paths=None, size=img_size, normalize=normalize_transform, transformations=None)\n",
    "\n",
    "temp = train_dataset.__getitem__(1)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(\n",
    "    dataset     = train_dataset,\n",
    "    batch_size  = config['batch_size'],\n",
    "    shuffle     = True,\n",
    "    num_workers = 4,\n",
    "    pin_memory  = True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset     = val_dataset,\n",
    "    batch_size  = config['batch_size'],\n",
    "    shuffle     = False,\n",
    "    num_workers = 2\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset     = test_dataset,\n",
    "    batch_size  = config['batch_size'],\n",
    "    shuffle     = False,\n",
    "    drop_last   = False,\n",
    "    num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-1.1915, -1.0216, -1.3952,  ..., -2.3227, -2.3106,  0.1408],\n",
      "          [-1.3971, -1.5565, -3.6995,  ..., -2.3611,  0.4789,  0.4479],\n",
      "          [-0.9319,  0.0875, -2.5249,  ..., -3.3560, -2.0224, -2.7261],\n",
      "          ...,\n",
      "          [-1.5556, -2.4516, -2.1156,  ..., -2.1118, -1.7232, -2.7438],\n",
      "          [-2.6119, -3.2381, -3.3083,  ..., -1.2819,  0.1450, -3.3783],\n",
      "          [-2.4591, -2.1086, -3.5836,  ..., -1.4152, -0.9050, -3.5213]]]])\n"
     ]
    }
   ],
   "source": [
    "model = Unet(\n",
    "    # backbone='convnext_base', # backbone network name\n",
    "    backbone='resnet50',\n",
    "    preprocessing=True,\n",
    "    in_channels=3, # input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    num_classes=config[\"num_classes\"],  # output channels (number of classes in your dataset)\n",
    "    encoder_freeze=True,\n",
    "    pretrained=True,\n",
    ")\n",
    "\n",
    "# model = model().to(device)\n",
    "random_tensor = torch.rand((1, 3, 1024, 1024))\n",
    "print(model.predict(random_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msushantj\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/sush/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sush/klab2/Segmentation_Models/pretrained-backbones-unet/wandb/run-20231130_114327-c9op1o3b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sushantj/IDL_Project_Segmentation/runs/c9op1o3b' target=\"_blank\">UNet_with_resnet_50</a></strong> to <a href='https://wandb.ai/sushantj/IDL_Project_Segmentation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sushantj/IDL_Project_Segmentation' target=\"_blank\">https://wandb.ai/sushantj/IDL_Project_Segmentation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sushantj/IDL_Project_Segmentation/runs/c9op1o3b' target=\"_blank\">https://wandb.ai/sushantj/IDL_Project_Segmentation/runs/c9op1o3b</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define wandb credentials\n",
    "\n",
    "import wandb\n",
    "wandb.login(key=\"49efd84d0e342f343fb91401332234dea4a3ffe2\") #API Key is in your wandb account, under settings (wandb.ai/settings)\n",
    "\n",
    "run = wandb.init(\n",
    "    name = \"UNet_with_resnet_50\", ## Wandb creates random run names if you skip this field\n",
    "    reinit = True, ### Allows reinitalizing runs when you re-run this cell\n",
    "    # run_id = ### Insert specific run id here if you want to resume a previous run\n",
    "    # resume = \"must\" ### You need this to resume previous runs, but comment out reinit = True when using this\n",
    "    project = \"IDL_Project_Segmentation\", ### Project should be created in your wandb account\n",
    "    config = config ### Wandb Config for your run\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = '/home/sush/klab2/Segmentation_Models/checkpoints/checkpoint.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|\u001b[32m██████████\u001b[0m| 98/98 [00:31<00:00,  3.12 training-batch/s, loss=0.344]\n",
      "Validation: 100%|\u001b[32m██████████\u001b[0m| 98/98 [00:11<00:00,  8.49 validating-batch/s, loss=0.996]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss 0.9963\n",
      "Saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:  41%|\u001b[32m████      \u001b[0m| 40/98 [00:13<00:20,  2.87 training-batch/s, loss=0.342]\n",
      "Traning Model on 10 epochs:  10%|█         | 1/10 [00:57<08:36, 57.37s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/sush/klab2/Segmentation_Models/pretrained-backbones-unet/unet_with_res50_segmentation.ipynb Cell 15\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sush/klab2/Segmentation_Models/pretrained-backbones-unet/unet_with_res50_segmentation.ipynb#X20sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m mixed_precision_scaler \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mamp\u001b[39m.\u001b[39mGradScaler()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sush/klab2/Segmentation_Models/pretrained-backbones-unet/unet_with_res50_segmentation.ipynb#X20sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sush/klab2/Segmentation_Models/pretrained-backbones-unet/unet_with_res50_segmentation.ipynb#X20sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     model\u001b[39m=\u001b[39mmodel,              \u001b[39m# UNet model with Resnet50 backbone\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sush/klab2/Segmentation_Models/pretrained-backbones-unet/unet_with_res50_segmentation.ipynb#X20sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     criterion\u001b[39m=\u001b[39mDiceLoss(),     \u001b[39m# loss function\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sush/klab2/Segmentation_Models/pretrained-backbones-unet/unet_with_res50_segmentation.ipynb#X20sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     checkpoint_path\u001b[39m=\u001b[39mcheckpoint_path\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sush/klab2/Segmentation_Models/pretrained-backbones-unet/unet_with_res50_segmentation.ipynb#X20sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/sush/klab2/Segmentation_Models/pretrained-backbones-unet/unet_with_res50_segmentation.ipynb#X20sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(train_loader, val_loader)\n",
      "File \u001b[0;32m~/klab2/Segmentation_Models/pretrained-backbones-unet/backbones_unet/utils/trainer.py:76\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, train_loader, val_loader)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[39m# ---- train process ----\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m trange(\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepochs \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, desc\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTraning Model on \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m epochs\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepochs)):\n\u001b[1;32m     75\u001b[0m     \u001b[39m# train\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_one_epoch(train_loader, epoch)\n\u001b[1;32m     77\u001b[0m     \u001b[39m# validate\u001b[39;00m\n\u001b[1;32m     78\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_evaluate(val_loader, epoch)\n",
      "File \u001b[0;32m~/klab2/Segmentation_Models/pretrained-backbones-unet/backbones_unet/utils/trainer.py:142\u001b[0m, in \u001b[0;36mTrainer._train_one_epoch\u001b[0;34m(self, data_loader, epoch)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlr_scheduler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    140\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlr_scheduler\u001b[39m.\u001b[39mstep()\n\u001b[0;32m--> 142\u001b[0m     training\u001b[39m.\u001b[39mset_postfix(loss\u001b[39m=\u001b[39mloss\u001b[39m.\u001b[39;49mitem())\n\u001b[1;32m    143\u001b[0m     losses[i] \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[1;32m    145\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_losses_[epoch \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m losses\u001b[39m.\u001b[39mmean()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.AdamW(params, lr=config['lr'], betas=(0.9, 0.999), weight_decay=0.05)\n",
    "gamma = 0.8\n",
    "milestones = [10,20,40,60,80]\n",
    "\n",
    "# scheduler1 = torch.optim.lr_scheduler.ConstantLR(optimizer, factor=0.9, total_iters=5)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=milestones, gamma=gamma)\n",
    "# scheduler3 = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
    "# scheduler = torch.optim.lr_scheduler.SequentialLR(optimizer, schedulers=[scheduler1, scheduler2, scheduler3], milestones=[20, 51])\n",
    "\n",
    "mixed_precision_scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,              # UNet model with Resnet50 backbone\n",
    "    criterion=DiceLoss(),     # loss function\n",
    "    optimizer=optimizer,\n",
    "    epochs=10,\n",
    "    # scaler=mixed_precision_scaler,\n",
    "    lr_scheduler=scheduler,\n",
    "    device=device,\n",
    "    checkpoint_path=checkpoint_path\n",
    ")\n",
    "\n",
    "trainer.fit(train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded scheduler state from checkpoint.\n",
      "Loaded checkpoint from: /home/sush/klab2/Segmentation_Models/checkpoints/checkpoint.pth\n",
      "Unet(\n",
      "  (encoder): FeatureListNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act1): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): UnetDecoder(\n",
      "    (center): Identity()\n",
      "    (blocks): ModuleList(\n",
      "      (0): DecoderBlock(\n",
      "        (conv1): Conv2dBnAct(\n",
      "          (conv): Conv2d(3072, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv2): Conv2dBnAct(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (1): DecoderBlock(\n",
      "        (conv1): Conv2dBnAct(\n",
      "          (conv): Conv2d(768, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv2): Conv2dBnAct(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (2): DecoderBlock(\n",
      "        (conv1): Conv2dBnAct(\n",
      "          (conv): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv2): Conv2dBnAct(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (3): DecoderBlock(\n",
      "        (conv1): Conv2dBnAct(\n",
      "          (conv): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv2): Conv2dBnAct(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (4): DecoderBlock(\n",
      "        (conv1): Conv2dBnAct(\n",
      "          (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "        (conv2): Conv2dBnAct(\n",
      "          (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Check if the checkpoint file exists\n",
    "if os.path.exists(checkpoint_path):\n",
    "    # If the checkpoint file exists, load the checkpoint\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']  # last epoch\n",
    "    val_loss = checkpoint['val_loss']  # Update the best accuracy\n",
    "    # Load the checkpoint and update the scheduler state if it exists in the checkpoint\n",
    "    if 'scheduler_state_dict' in checkpoint:\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        print(\"Loaded scheduler state from checkpoint.\")\n",
    "    else:\n",
    "        print(\"No scheduler state found in checkpoint.\")\n",
    "    print(\"Loaded checkpoint from:\", checkpoint_path)\n",
    "else:\n",
    "    # If the checkpoint file does not exist, start training from scratch\n",
    "    start_epoch = 0\n",
    "    print(\"No checkpoint found at:\", checkpoint_path)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
